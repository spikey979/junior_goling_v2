# ===== Application =====
# HTTP port for the service (container)
PORT=8080

# Host port mapping for docker-compose (change if 8080 is taken)
HOST_PORT=8080

# Run dispatcher workers inside the same process (1=yes, 0=no)
RUN_DISPATCHER=1

# Basic auth for the dashboard (required)
WEB_USERNAME=admin
WEB_PASSWORD=changeme


# ===== Logging =====
# Global log level: debug|info|warn|error
LOG_LEVEL=info
#panic - Samo kritični crashevi
#fatal - Fatal errors i panic
#error - Samo greške
#warn - Warnings i greške
#info - Info, warnings, errors (DEFAULT za produkciju)
#debug - Debug + sve gore (za development)
#trace - Najdetaljnije (za troubleshooting)

# Pretty console logs (true in dev)
LOG_PRETTY=true

# Log file path (rotated via lumberjack)
LOG_FILE=logs/aidispathcher.log

# Log rotation settings
LOG_MAX_SIZE_MB=100
LOG_MAX_BACKUPS=10
LOG_MAX_AGE_DAYS=30
LOG_COMPRESS=true


# ===== Queue / Redis =====
# Redis connection string (compose service name is "redis")
REDIS_URL=redis://redis:6379

# Redis Streams names
QUEUE_STREAM=jobs:ai:pages
QUEUE_GROUP=workers:images

# Polling interval for delayed mover and depth sampler
QUEUE_POLL_INTERVAL=100ms


# ===== Providers / Models =====
# Primary/secondary provider routing (openai|anthropic)
PRIMARY_ENGINE=openai
SECONDARY_ENGINE=anthropic

# OpenAI models
OPENAI_PRIMARY_MODEL=gpt-4.1
OPENAI_SECONDARY_MODEL=gpt-4o
OPENAI_FAST_MODEL=gpt-4.1-mini

# Anthropic models
ANTHROPIC_PRIMARY_MODEL=claude-3-5-sonnet
ANTHROPIC_SECONDARY_MODEL=claude-3-opus
ANTHROPIC_FAST_MODEL=claude-3-haiku


# ===== Timeouts / Retries =====
# Default per-request timeout; provider-specific override if set
REQUEST_TIMEOUT=60s
OPENAI_TIMEOUT=
ANTHROPIC_TIMEOUT=

# Max wall-time per page (overall)
PAGE_TOTAL_TIMEOUT=120s

# Retry policy
JOB_MAX_ATTEMPTS=3
RETRY_BASE_DELAY=2s
RETRY_BACKOFF_FACTOR=2.0
RETRY_JITTER=200ms


# ===== Adaptive limiter / Breaker =====
# Max in-flight requests per provider:model in this process
MAX_INFLIGHT_PER_MODEL=2

# Circuit-breaker cooldowns for 429/transient errors
BREAKER_BASE_BACKOFF=30s
BREAKER_MAX_BACKOFF=5m


# ===== AI API Keys (read directly by clients) =====
# Set at runtime; clients read from env inside container
OPENAI_API_KEY=
ANTHROPIC_API_KEY=


# ===== AWS / S3 (optional) =====
# When running with docker-compose, ${HOME}/.aws is mounted into the container
# and AWS_SDK_LOAD_CONFIG=1 is set. Provide the profile name to use here.
AWS_PROFILE=

# Region and bucket used for reading PDFs and storing results (if S3 used)
AWS_REGION=
AWS_S3_BUCKET=

# Enable versioning of S3 results (upload to _vN and promote to base)
RESULT_VERSIONING_ENABLED=


# ===== Axiom (optional) =====
SEND_LOGS_TO_AXIOM=0
AXIOM_API_KEY=
AXIOM_ORG_ID=
AXIOM_DATASET=dev
